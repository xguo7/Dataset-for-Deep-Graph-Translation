# Dataset-for-Deep-Graph-Translation
This page summarize and provide the data and applications for the deep graph translation problem. The deep graph translation problem aims to learn the mapping rules among graphs atomatically by oberving large amount of graph pairs based on the deep learning methods. There are two versions of deep graph translation problems: one is to learn a one-to-one mapping rule between the input graph and target graph, as the defination by Guo et al [1]; another is to learn a one-to-many mapping rule between the input graph and a set of target graphs, which is defined by Guo et al [2]; To avoid loss of generality, the graph in this problems can be all kinds of graphs, such as directed/undirected graphs, sign graphs, and multi-attributed graph. 

![image_text](images/graph_translation.png "Deep Graph Translation")

For wider investigation and explaration by researchers around the world, we provide five synthetic or real-world data as well as their application tasks for this problem: Scale-free graphs dataset, IoT (Internet of Things) dataset, Brainnetwork connectivety dataset, User authenticfication dataset, and the chemistry reaction dataset. 
    
    
## Scale-free Graphs 
This dataset fits the "one-to-many" mapping graph translation version. There are no node features in the dataset, and the goal is to learn the mapping from the input graphs' topology to the target graph's topology. Each input graph is generated as a directed scalefree network, which is a network whose degree distribution follows power-law property (Bollobas´ et al., 2003). To generate a target graph, a node will by selected as target node with probability proportional to its in-degree, which will be linked to a new source node with probability of 0.41. Similarly, a node will by selected as source node with probability proportional to its out-degree, which will be linked to a new target node with probability of 0.54. Then, a corresponding target graph is generated by adding m (m equals the number of nodes of the input graph) edges between two nodes. Thus, both input and target graphs are directed scale-free graphs. 


#### Content
There are five subsets of data with different graph size (i.e. number of nodes): 10, 20, 50, 100, and 150. In each subset, each input and output graph are stored in the "scale-(graph_size)-input-index.csv" and "scale-(graph_size)-target-index.csv" file. For each file, the value in i(th) comlume, j(th) row indicates whether the number of connections (edge weights) between Node i and Node j (1 indicating there is an edge and 0 otherwise). These dataset can be downloaded through the following links:

[Scale_free_150](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EQ7FRL8QWYdPg25QaCe0VpEBHwioyA4nEjP2GDgiVQQwVw)

[scale_free_100](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EXLsRjyz7z1HhRur-F9jkpwBFfRhO14NfQxXoLSHwCzYfg)

[scale_free_50](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/Ec7OxxtCrW5Nr7itfQAlcagBQaRNG-ttRt-DZkj8jBxphQ)

[scale_free_20](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EQ3WsWoTBwNLsQXQOIwChOgBsbDIUfZpp0tmvJYGp0JrtA)

[scale_free_10](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EartEwo94NtJrsBUSDCaSyIBYgHxLSVj6qwziixaQHHHdw)

#### Acknowledgements
Please cite formally when you use these dataset as:

Guo, X., Wu, L., & Zhao, L. (2018). Deep graph translation. arXiv preprint arXiv:1805.09980.

## Erdos-Renyi Graphs
This dataset fit the problem of "one-to-one" mapping verision of graph translation. For each pair of graphs, the input graph is generated by the Erdos Renyi model with the edge probability of 0.2. The target graph topology is the 2-hop connection of the input graph, where each edge in the target graph refers to the 2-hop reachability in the input graph (e.g. if node i is 2-hop reachable to node j in the input graph, then they are connected in the target graph). There are edge and node attributes for graphs in this dataset: the edge attributes E_(i,j) denotes the existence of the edge and the node attributes are continuous values computed following the polynomial function: f(x) : y = ax^2 + bx + c(a =0; b =1; c= 5), where x is the node degree and f(x) is the node attribute.

#### Contents
There are three subsets of data with different graph size (i.e. number of nodes): 20, 40, and 60. In each subset, each input and output graph are stored in the "ER-(graph_size)-input-index.csv" and "ER-(graph_size)-target-index.csv" file. For each file, the value in i(th) comlume, j(th) row indicates whether the number of connections (edge weights) between Node i and Node j (1 indicating there is an edge and 0 otherwise). The value in i(th) row and i(th) column indicates the node attributes of the i(th) node. These dataset can be downloaded through the following links:

[ER_20](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EacBEmToBKdPtOhjJocARikBV6WRr7kNs50QyFShsx1k1w)

[ER_40](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EU7TdmWC_z1HvY3KLcPonZwBB167_MYTQZuW8wSso4Qc1g)

[ER_60](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EQYmsg6wu3ZAuvHS1Klc_gwBdZP3jCl_PM2p6p7nLMZ66g)

#### Acknowledgements
Please cite formally when you use these dataset as:

Guo X, Zhao L, Nowzari C, Rafatirad S, Homayoun H, Dinakarrao SM. Deep Multi-attributed Graph Translation with Node-Edge Co-evolution. Inhe 19th International Conference on Data Mining (ICDM 2019), pp. to appear 2019.

## Barab´asi-Albert Graphs
This dataset fit the problem of "one-to-one" mapping verision of graph translation. For each pair of graphs, the input graph is generated by the Barab´asi-Albert model. The target graph topology is the 2-hop connection of the input graph, where each edge in the target graph refers to the 3-hop reachability in the input graph (e.g. if node i is 3-hop reachable to node j in the input graph, then they are connected in the target graph). There are edge and node attributes for graphs in this dataset: the edge attributes E_(i,j) denotes the existence of the edge and the node attributes are continuous values computed following the polynomial function: f(x) : y = ax^2 + bx + c(a =0; b =1; c= 5), where x is the node degree and f(x) is the node attribute.

#### Contents
There are three subsets of data with different graph size (i.e. number of nodes): 20, 40, and 60. In each subset, each input and output graph are stored in the "BA-(graph_size)-input-index.csv" and "BA-(graph_size)-target-index.csv" file. For each file, the value in i(th) comlume, j(th) row indicates whether the number of connections (edge weights) between Node i and Node j (1 indicating there is an edge and 0 otherwise). The value in i(th) row and i(th) column indicates the node attributes of the i(th) node. These dataset can be downloaded through the following links:

[BA_20](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/ESU5immRQ3xCvxkAy0LFvlgBTJrF0eHDosjRhnnayUXqHw)

[BA_40](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EaihwXZdW2dHpl0X22dtD5wBcKFD9X6F1SoYhDKzAhRX1w)

[BA_60](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EV96-W8Kw1hFnMxDudDWCk0BK6J24_my2yD7KrgJLR-yWw)

#### Acknowledgements
Please cite formally when you use these dataset as:

Guo X, Zhao L, Nowzari C, Rafatirad S, Homayoun H, Dinakarrao SM. Deep Multi-attributed Graph Translation with Node-Edge Co-evolution. Inhe 19th International Conference on Data Mining (ICDM 2019), pp. to appear 2019.


## IoT 

#### Problem Background
The process of malware confinement over IoT (Internet of Things) is typically a graph translation problem. A device infected in an IoT network can propagate to other nodes connected to it, leading to contaminating the whole network, such as MiraiBot attack. As such, it is non-trivial to confine the malware to limit the infection and also equally important to maintain overall network connectivity and
performance. The malware confinement takes the initial status of IoT as input, and predicts the target graph which is ideally the optimal status of the network with modified connections (i.e., edges) and devices (i.e., nodes) state that helps to limit malware propagation and maintain network throughput. Tranditional malware confinement are based on ad-hoc methods, which heavily rely on intensive handcrafting and domain-specific mechanistic models that could be extremely time- and resource- consuming to run in large scale. Hence, a generic, efficient, and end-to-end method is in demand, which is able to comprehensively learn the translation mapping, remedy human bias by enjoying the large historical data, and achieve efficient prediction.

#### Dataset Collection
Malware dataset are collected for malware confinement prediction. There are three sets of IoT nodes at different amount (20, 40 and 60) encompassing temperature sensors connected with Intel ATLASEDGE Board and Beagle Boards (BeagleBone Blue), communicating via Bluetooth protocol. Benign and malware activities are executed on these devices to generate the initial attacked networks as the input graphs. Benign activities include MiBench [34] and SPEC2006 [35], Linux system programs, and word processor. The nodes represent devices and node attribute is a binary value referring to whether the device is compromised or not. Edge represents the connection of two devices and the edge attribute is a continuous value reflecting the distance of two devices. The real target graphs are generated by the classical malware confinement methods: stochastic controlling with malware detection. We collected 334 pairs of input and target graphs with different contextual parameters (infection rate, recovery rate, and decay rate) for each of the three datasets. In this dataset, there are both nodes attributes and edge attributes considered.

#### Description
There are three subsets with different graph sizes. Each input/target graph is stored in the file with name " IoT-[graph_size]-[input/output]-[infection rate]-[recovery rate]-[decay rate]-[index].csv". The infection rate, recovery rate and decay rate can be used as the contextual controlling parameters in generating the target graph. The value of i(th) row and j(th) colomn refers to the phsical distance of Node i and j (0 refers to no links). The value of i(th) row and i(th) colomn refers to the node attribute (i.e. device status) of the Node i. 

[IoT_20](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EcZsWKkLcxBKpaZ-X7_CHcoB5VAEzd9AGYgxATWIUPAsRw)

[IoT_40](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/Eekr5lVPZBlMk6_1KkBgZbIBWPRYzDrA6tt9WOhJ1yUbEA)

[IoT_60](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EY6Emi5mPQdDodCY0dK_ISQB4oYGpRnaMfxY2EpSCE7VLw)

#### Acknowledgements
Please cite formally when you use these dataset as:

Guo X, Zhao L, Nowzari C, Rafatirad S, Homayoun H, Dinakarrao SM. Deep Multi-attributed Graph Translation with Node-Edge Co-evolution. Inhe 19th International Conference on Data Mining (ICDM 2019), pp. to appear 2019.


## User Authetication

#### Problem Background 
Important trade secrets stored in an enterprise’s computer network are extremely hard to defend from theft-of-trade-secret behaviors, which involve highly sophisticated activities in terms of malicious authentication paths over cyber-networks. Malicious detection involves learning from rich historical attack examples, which however are not available for all the employee accounts. The generic distribution of theft behaviors from historical attacks on some accounts can be learned and used to synthesize a range of possible malicious authentication graphs for other accounts based on their regular authentication graphs. 

#### Data Collection
The goal of this application was to forecast future potential users' malicious authentication graphs given the user’s normal authentication graph, which is an one-to-many mapping version of graph translation. This dataset includes the authentication activities of 97 users on their accessible computers and servers in an enterprise computer network (Kent, 2015). Each user account generates a log file recording the computer accessing history, which could be formulated as a directed weighted graph called authentication graph, where nodes represent computers and the directed edges weights represent the authentication activities with certain frequencies. This data set spans one calendar year of contiguous activity spanning 2012 and 2013. It originated from 33.9 billion raw event logs (1.4 terabytes compressed) collected across the LANL enterprise network of approximately 24,000 computers. The input graphs represent authentication events collected from individualWindows-based desktop computers, servers, and Active Directory servers. The target graphs present specific events taken from the authentication data that present known red team compromise events, as we call malicious event. The red team data can used as ground truth of bad behavior which is different from normal user. Each graph can represent the log-on activity of one user in a time window. This task is the one-many-mapping, which means for each input graph, there can be many potential target graphs that follows the same distribution.

#### Description
There are two subsets of different sizes of graphs (i.e., 50 and 300). For each subset, we have train anf test folder seperately. Train set contains the graph pairs (one-to-one) which are just used for training. Test set contains data for each user. For each user, there are several input graphs (i.e. regular user authentication activity graph) and several target graphs (i.e. malware user authentication acticity graph). There input and target graphs in test set are not one-to-one, which can be tested by indirect evaluation. There is no node attributes for this dataset, and only edge attribute is considered.
For each graph, the value of i(th) row and j(th) colomn refers to the edge attribute of Node i and j (0 refers to no links).

[Auth_50](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/Ed5FSLojkadImn4PvDgln_8B6pCP0oePBXbq-osyDpBcFQ)

[Auth_300](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EbEM8KApJhlAuReZTsgzBjkBv4zVYpKOtLuE7ZK0J46q-w)
#### Acknowledgements
Please cite formally when you use these dataset as:

Guo, X., Wu, L., & Zhao, L. (2018). Deep graph translation. arXiv preprint arXiv:1805.09980.

## Chemistry Reaction

#### Problem Background
Reaction prediction remains one of the major challenges for organic chemistry and is a prerequisite for efficient synthetic planning. It is desirable to develop algorithms that, like humans, “learn” from being exposed to examples of the application of the rules of organic chemistry. 

#### Data Collection
The chemistry preaction product prediction can be formalized as the graph translation problem, thus predicting the product (target graph) of chemical reaction given the reactant (input graph). Each molecular graph consists of atoms as nodes and bond as edges. The input molecule graph has multiple connected components since there are multiple molecules comprising the reactants. The reactions used for training are atom-mapped so that each atom in the product graph has a unique corresponding atom in the reactants. We collected reactions from USPTO granted patents (Lowe, 2014). we obtained a set of 5,000 reactions (reactant-product pair). Atom (node) features include its elemental identity, degree of connectivity, number of attached hydrogen atoms, implicit valence, and aromaticity. Bond (edge) features include bond type (single, double, triple, or aromatic), and whether it is connected.

#### Description
There are totally 7180 pairs of reactant anf product molecule graph in the dataset. The number of nodes (atoms) of molecule ranges from 9 to 20, and the number of atoms for each pair is recorded and stored in the file "Num_nodes.cxv". The file folder "mol_edge" store all the adjacent matrix for the input and target graph. The dimension of the adjacent matrix is 20 by 20, and for those graphs whose nodes are less than 20, we use zero to pad. The values in adjacent matrix is in [0,1,2,3,4] representing five bond types (none, single, double, triple, or aromatic). The folder "Mol_nodes" stores the node features for all the nodes in each graph. The node feature indicates the atom type (82 types) which are embedded by one-hot vector with 82 dimensions. In this problem setting, the node feature remains unchanged during the translation.

[Mol_edge](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EZzBXqVYGQZBijWzB6XV-k4BYrQjJp4J2GKDPlhYdDfkqw)

[Mol_nodes](https://exchangelabsgmu-my.sharepoint.com/:u:/g/personal/xguo7_masonlive_gmu_edu/EWPhBYlZ8x1Ptn5esMqaKOABa11TAt_7UJrYmSGHBowpBg)

[Num_nodes](https://exchangelabsgmu-my.sharepoint.com/:x:/g/personal/xguo7_masonlive_gmu_edu/EVLlh7btdvxPgsZaym_TyA4BQnyqE_oNE_jfEtM2v1gbTA)

More datasets of chemical reaction can be found in [USPTO-15K](https://github.com/wengong-jin/nips17-rexgen).

#### Acknowledgements
Please cite formally when you use these dataset as:

Guo X, Zhao L, Nowzari C, Rafatirad S, Homayoun H, Dinakarrao SM. Deep Multi-attributed Graph Translation with Node-Edge Co-evolution. Inhe 19th International Conference on Data Mining (ICDM 2019), pp. to appear 2019.

D. Lowe, “Patent reaction extraction: downloads,” 2014.

## Molecule Optimization
#### Problem Background
The goal of drug discovery is to design molecules with desirable chemical properties. The task is challenging since the chemical space is vast and often difficult to navigate. One of the prevailing approaches, known as matched molecular pair analysis (MMPA), learns rules for generating “molecular paraphrases” that are likely to improve target chemical properties. The setup is analogous to machine translation: MMPA takes as input molecular pairs f(X; Y )g, where Y is a paraphrase of X with better chemical properties. However, current MMPA methods distill the matched pairs into graph transformation rules rather than treating it as a general translation problem over graphs based on parallel data. Molecular optimization can be formalized as graph-to-graph translation. Given a corpus of molecular pairs, the goal is to learn to translate input molecular graphs into better graphs.

#### Data Collection
Following standard practice in MMPA, we construct training sets by sampling molecular pairs (X; Y ) with significant property improvement and molecular similarity sim(X; Y ). The similarity constraint is also enforced at evaluation time to exclude arbitrary mappings that completely ignore the input X. We measure the molecular similarity by computing Tanimoto similarity over Morgan fingerprints (Rogers & Hahn, 2010). Next we describe how these tasks are constructed.

#### Dataset Decription
[Penalized logP](https://github.com/wengong-jin/iclr19-graph2graph/tree/master/data) The goal is to improve the penalized logP score of molecules under the similarity constraint. We experiment with two similarity constraints(0.4 and 0.6), and we extracted 99K and 79K translation pairs respectively from the ZINC dataset for training. 

[Drug likeness (QED)](https://github.com/wengong-jin/iclr19-graph2graph/tree/master/data/qed) This task is to improve drug likeness of compounds. Specifically, the model needs to translate molecules with QED scores (Bickerton et al., 2012) within the range (0.7-0.8) into the higher range (0.9-1.0). This task is challenging as the target range contains only the top 6.6% of molecules in the ZINC dataset. We extracted a training set of 88K molecule pairs with similarity constraint (0.4). The test set contains 800 molecules.

[Dopamine Receptor (DRD2)](https://github.com/wengong-jin/iclr19-graph2graph/tree/master/data/drd2) This task is to improve a molecule’s biological activity against a biological target named the dopamine type 2 receptor (DRD2). We use a trained model from Olivecrona et al. (2017) to assess the probability that a compound is active. We ask the model to translate molecules with predicted probability p < 0:05 into active compounds with p > 0.5. The active compounds represent only 1.9% of the dataset. With similarity constraint 0.4, we derived a training set of 34K molecular pairs from ZINC. The test set contains 1000 molecules.

#### Acknowledgements
Please cite formally when you use these dataset as:

Jin, W., Yang, K., Barzilay, R., & Jaakkola, T. (2018). Learning multimodal graph-to-graph translation for molecular optimization. arXiv preprint arXiv:1812.01070.

## Circuit Simplification
#### Data Collection 
In circuit simplification, a logical expression is reduced to a logically equivalent expression with fewer operations. We construct a dataset of random circuits with 15-30 nodes (3-8 variables). Each node in the graph corresponds to one of four node types: variables, NOT-gates, OR-gates, and AND-gates. Node features are given by a one-hot encoding of the four node types. All generated circuits were valid, i.e. they have a single sink node, NOT-gate nodes have a single input, variable nodes have no inputs, and OR and AND-gate nodes have at least two inputs. To produce ground truth simplifications, the generated logical expressions corresponding to each graphs were simplified using the Sympy Python library, which provides an equivalent expression either in conjunctive normal form (CNF) or disjunctive normal form (DNF), depending on which is more compact. Any circuits that simplified to True (tautology) or False (unsatisfiable) were excluded. We use 10,000 circuit pairs for training and 2,500 pairs for testing. Node features are given
by a one-hot encoding of the four node types.
[Circuit dataset] (https://github.com/claradepaolis/D2DRNN)

#### Acknowledgements
Please cite formally when you use these dataset as:

Kaluza, M. C. D. P., Amizadeh, S., & Yu, R. A Neural Framework for Learning DAG to DAG Translation.


## Brainnetwork  
#### Description
#### Acknowledgements
